{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Willow Is a Practical, Open Source, Privacy-focused Platform for Voice Assistants and Other Applications","text":"<p>Willow is an ESP IDF based project primarily targeting the ESP32-S3-BOX hardware from Espressif. Our goal is to provide Amazon Echo/Google Home competitive performance, accuracy, cost and functionality with Home Assistant, openHAB and other platforms.</p> <p>100% open source and completely self-hosted by the user with \"ready for the kitchen counter\" low cost commercially available hardware.</p> <p>FAST - Response times faster than Alexa/Echo or Google Home. From end of speech to action completed in 500ms or less. If you're curious how it's so fast (and accurate) you can watch the technical deep dive.</p> <p>ACCURATE - High wake word accuracy, low false activation, and speech recognition powered by our Willow Inference Server or command recognition solely on the device.</p> <p>RELIABLE - We've tested thousands of cycles of voice commands with a &lt; 1% failure rate. No one likes to repeat themselves!</p> <p>FLEXIBLE - Use Willow Inference Server anywhere or don't use it at all with command recognition on the device. Have the results go anywhere you want. Integrate with whatever you want. Completely open source so it does what you want, only what you want, and only how you want it. No more annoying extra prompts or sales pitches to upsell you. Supports multiple wake words with more coming soon.</p> <p>PRIVATE - Check the source. Build and flash yourself. Proxy through another server to inspect traffic. Use on your own server. Use only local commands. Use on a network without access to the internet. Dig as deep as you want because you're not going to find anything fishy here!</p> <p>PRACTICAL AND NOT UGLY - Ready to go! Take it out of the box, flash, and put it in your home or office in minutes without getting looks from people wondering what that \"thing\" is. Install as many as you like.</p> <p>CHEAP - Approximately $50 hardware cost (plus USB-C power supply). Fully assembled. Done.</p> <p>LOW POWER - 100mW power usage.</p> <p>Current supported features include:</p> <ul> <li>Wake Word Engine. Say \"Hi ESP\" or \"Alexa\" (user selectable) and start talking!</li> <li>Voice Activity Detection. When you stop talking it will stop listening and take action.</li> <li>Support for Home Assistant, openHAB and generic REST APIs! </li> <li>Support for other platforms. As long as your configured endpoint can take an HTTP POST you can do anything with the speech output!</li> <li>Great far-field performance. We've tested wake and speech recognition from roughly 25 feet away in challenging environments with good results.</li> <li>Great audio quality. Willow provides features such as automatic gain control, acoustic echo cancellation, noise suppression, blind source separation, etc.</li> <li>Support for challenging Wi-Fi environments. Willow can (optionally) use audio compression to reduce airtime on 2.4 GHz Wi-Fi in cases where it's very busy.</li> <li>LCD and touchscreen. The ESP32-S3-BOX has color LCD and capacitive multi-point touchscreen. We support them with an initial user interface.</li> <li>Completely on device speech command recognition and support for our open source Willow Inference Server (Tovera hosted best-effort WIS provided). Configure up to 400 commands completely on device or self-host our inference server to transcribe any speech!</li> </ul> <p>All with hardware you can order online today (Amazon, AliExpress, Adafruit, The Pi Hut, Mouser and many others) for around $50 USD. Add a USB-C power supply and go!</p>"},{"location":"development/","title":"Development","text":"<p>Configuring and building Willow for the ESP BOX is a multi-step process that is required if you want to do Willow development. We've provided a helper script to make things easier.</p>"},{"location":"development/#build-willow","title":"Build Willow","text":""},{"location":"development/#install-system-dependencies","title":"Install System Dependencies","text":"<p>We use tio as a serial monitor so you will need to install that.</p> Ubuntu/DebianArch LinuxMac (with homebrew) <pre><code>sudo apt-get install tio\n</code></pre> <pre><code>yay -S tio\n</code></pre> <pre><code>brew install tio\n</code></pre>"},{"location":"development/#clone-willow-repo","title":"Clone Willow Repo","text":"<pre><code>git clone https://github.com/toverainc/willow.git &amp;&amp; cd willow\n</code></pre>"},{"location":"development/#build-willow-development-docker-container","title":"Build Willow Development Docker Container","text":"<p>We use Docker (also supports Podman) for the build container. To build the container with Docker:</p> <pre><code>./utils.sh build-docker\n</code></pre>"},{"location":"development/#start-willow-development-docker-container","title":"Start Willow Development Docker Container","text":"<p>Once the container has finished building you will need to enter it for all following commands:</p> <pre><code>./utils.sh docker\n</code></pre>"},{"location":"development/#install-build-environment","title":"Install Build Environment","text":"<p>Once inside the container install the environment:</p> <pre><code>./utils.sh install\n</code></pre>"},{"location":"development/#start-configuration","title":"Start Configuration","text":"<p>Start the Willow configuration process:</p> <pre><code>./utils.sh config\n</code></pre> <p>ESP BOX LITE NOTE!!!</p> <p>You will need to build specifically for the ESP BOX LITE. From the main menu, select:</p> <p>Audio HAL ---&gt; Audio Board ---&gt; ESP32-S3-BOX-Lite</p> <p>Return to main menu and continue.</p>"},{"location":"development/#willow-configuration","title":"Willow Configuration","text":"<p>Navigate to Willow Configuration to enter your Wi-Fi SSID and password (supports 2.4 GHz Wi-Fi with WPA/WPA2/WPA3 authentication), and your Willow Application Server URL.</p> <p>Once you've provided these press Q and save when prompted.</p>"},{"location":"development/#build-and-exit-container","title":"Build and Exit Container","text":"<pre><code>./utils.sh build\n</code></pre> <p>When the build completes successfully you can exit the container.</p>"},{"location":"development/#flash-willow-to-your-device","title":"Flash Willow to Your Device","text":"<p>It's getting real now - plug the ESP32-S3-BOX in!</p>"},{"location":"development/#set-serial-port","title":"Set Serial Port","text":"<p>Back on the host docker:</p> <p>To do anything involving the serial port you will need to set the <code>PORT</code> environment variable for all further invocations of <code>utils.sh</code>.</p> <p>With recent versions of <code>tio</code> you can use <code>tio -L</code> to list available ports. On Linux you can check <code>dmesg</code> and look for the path of the recently connected ESP32-S3-BOX (furthest at the bottom, hopefully). On Linux it's usually <code>/dev/ACM*</code> and on Mac it's <code>/dev/usbmodem*</code>.</p> <p>Examples</p> LinuxMac <pre><code>export PORT=/dev/ttyACM0\n</code></pre> <pre><code>export PORT=/dev/cu.usbmodem2101\n</code></pre>"},{"location":"development/#flash","title":"Flash","text":"<p>For out of the box/factory new ESP32-S3-BOX hardware you will need to (one time) erase the factory flash before flashing Willow:</p> <pre><code>./utils.sh erase-flash\n</code></pre> <p>Once you have done that you can flash</p> <pre><code>./utils.sh flash\n</code></pre> <p>It should flash and connect you to the serial monitor.</p> <p>If you're encountering flashing issues due to USB passthrough use <code>willow-dist.bin</code> and flash it from a another computer</p>"},{"location":"development/#flash-from-another-device","title":"Flash from Another Device","text":"<p>If you want to quickly and easily flash multiple devices or distribute a combined firmware image you can use the <code>dist</code> arguments to <code>utils.sh</code>:</p> <p><code>./utils.sh dist</code> - builds the combined flash image (<code>willow-dist.bin</code>)</p> <p><code>./utils.sh flash-dist</code> - flashes the combined flash image </p> <p>This combined firmware image can be used with any ESP flashing tool.</p>"},{"location":"development/#advanced-options","title":"Advanced Options","text":"<p><code>utils.sh</code> will attempt to load environment variables from <code>.env</code>. You can define your <code>PORT</code> here to avoid needing to define it over and over.</p> <p>The ESP-IDF, ESP-ADF, ESP-SR, LVGL, etc. libraries have a plethora of configuration options. DO NOT change anything outside of Willow Configuration (other than wake word) unless you know what you are doing.</p>"},{"location":"development/#exit-serial-monitor","title":"Exit Serial monitor","text":"<p>To exit <code>tio</code> you need to press Ctrl+T and then Q. Or you can unplug your device and <code>tio</code> will wait until you reconnect it.</p>"},{"location":"development/#start-serial-monitor","title":"Start Serial monitor","text":"<p>If you want to see what your device is up to you can start the serial monitor anytime:</p> <pre><code>./utils.sh monitor\n</code></pre>"},{"location":"development/#things-went-sideways-reset","title":"Things Went Sideways - Reset!","text":"<p>In the event your environment gets out of whack we have a helper to reset:</p> <pre><code>./utils.sh destroy\n</code></pre> <p>As the plentiful messages indicate it's a destructive process but it will reset your environment. After it completes you can start from the top and try again.</p>"},{"location":"development/#recovery","title":"Recovery","text":"<p>Recover from a bad flash or persistent flash failures.</p> <p>In some hardware combinations the ESP32-S3-BOX can be stubborn and won't successfully flash.</p> <p>In these cases, press the BOOT/CONFIG button (top button on the left side) while powering up the device, then:</p> <p>Erase the flash:</p> <pre><code>./utils.sh erase-flash\n</code></pre> <p>Tip</p> <p>Depending on how tight of a boot loop your device is in, you may need to run <code>erase-flash</code> multiple times to get the timing right. It will eventually \"catch\" and successfully erase the flash.</p> <p>When it reports successful erase you can flash again with: <pre><code>./utils.sh flash\n</code></pre></p>"},{"location":"get-involved/","title":"Get Involved!","text":"<p>Join Github discussions to stop by, introduce yourself, and let us know how things are going with Willow!</p>"},{"location":"hardware/","title":"Hardware","text":"<p>The ESP32-S3-BOX is the primary supported hardware platform for Willow. It's what we develop on, it's what we target, and it's what we support.</p>"},{"location":"hardware/#esp32-s3-box","title":"ESP32-S3-BOX","text":"<p>Out of the box the ESP32-S3-BOX is near perfect for Willow. However, in a perfect world there is one manufacturing change we would make...</p>"},{"location":"hardware/#power-led-hack","title":"Power LED Hack","text":"<p>The green power LED on the top right of the enclosure is not connected via GPIO. Per the schematic it is connected directly to a 3.3v buck converter coming from 5 VIN. Because of this it is EXTREMELY bright. For many usage scenarios we suggest that more advanced (and brave) users disable this LED.</p> <p>Opening the enclosure always runs the risk of breaking something!</p> <p>If you accept this risk you can disable the power LED by opening the enclosure and de-soldering or breaking it off the PCB. We have successfully done this across several boxes without issue.</p> <p>It is our hope that in future revisions Espressif connects this LED via GPIO so we can control its function, brightness, etc.</p>"},{"location":"hardware/#esp32-s3-box-lite","title":"ESP32-S3-BOX-Lite","text":"<p>We DO NOT recommend purchasing an ESP32-S3-BOX-Lite for Willow.</p> <p>The Lite is a variant of the BOX that doesn't include a dock or touchscreen. We don't recommend it because the lack of a dock and touch screen limits what you can do with Willow!</p>"},{"location":"hardware/#esp32-s3-box-3","title":"ESP32-S3-BOX-3","text":"<p>The new BOX-3 is an ESP BOX that supports additional modules like sensors, breadboards, and more.</p> <p>We have hardware samples coming and will support it very soon.</p>"},{"location":"hardware/#power-supplies","title":"Power Supplies","text":"<p>ESP Boxes are very low power. They call for a 5V 1A power supply and we have observed the ESP32-S3-BOX using a fraction of that. However, we haven't been able to find readily-available (CHEAP) lower amperage (1A) USB-C power supplies for the ESP32-S3-BOX. If you know where to get one let us know!</p>"},{"location":"hardware/#expansion-gpio-etc","title":"Expansion (GPIO, etc)","text":"<p>EXP Boxes expose 16 rear GPIOs that enable users to have the best of both worlds - an attractive and ready to go enclosure that would not look out of place in any installation but also exposes more advanced \"maker-type\" functionality.</p> <p>We are currently considering the best way to go about user control of these GPIOs. Ideally we could use esphome or some other established/standard way to configure them but we haven't completely thought this through yet.</p>"},{"location":"hardware/#other-esp32-s3-based-boards","title":"Other ESP32-S3 Based Boards","text":"<p>The ESP32 S3 is what really \"makes the magic happen\" for Willow as the high speed PSRAM enables a lot of the more advanced neural features. It is certainly possible that Willow can run on other ESP32-S3 based boards but supporting these is up to you!</p> <p>In the future we may officially support other ESP32-S3 (or successor series) based boards but they are not supported at this time.</p>"},{"location":"hardware/#other-espressif-boards","title":"Other Espressif Boards","text":"<p>Per the ESP ADF and ESP-SR documentation regular plain 'ol ESP32 boards can run some speech features. However, they are so limited the experience isn't what we would call acceptable to meet our goals of removing creepy corporate microphones from your environment without any compromises.</p> <p>We have not investigated support for any other ESP32 based platforms such as the C series.</p>"},{"location":"how-willow-works/","title":"How Willow Works","text":""},{"location":"how-willow-works/#software-architecture","title":"Software Architecture","text":"<p>The root of the project is the Espressif Audio Development Framework (ESP-ADF). We use the ESP-ADF because it enables fairly straightforward management of \"audio pipelines\" that we use for I2S access to the audio hardware, connection to the recorder, streaming to the inference server, and optional support of AMR-WB for audio compression. In the future for audio playback support, etc. we will have additional audio playback pipelines to stream music, etc. The ESP-ADF then uses the ESP-IDF as a component. This is somewhat counter-intuitive as the ESP-ADF depends on the ESP IDF and one would think this would be the other way around.</p> <p>We then (manually) pull in a more recent version of the ESP-SR Speech Recognition Framework. ESP-SR is what enables the AFE (Audio Front End) that performs things such as AGC (Automatic Gain Control), etc. Additionally, it provides wake word detection, local command recognition via MultiNet, etc.</p> <p>We also use various \"managed components\" to support things like the LCD, etc.</p>"},{"location":"how-willow-works/#whats-with-the-goofy-on-the-wire-format","title":"What\u2019s With the Goofy on the Wire Format?","text":"<p>Many developers are familiar with things like WebRTC. Again, due to my years in VoIP I certainly am. At first glance Willow may seem like a good application for WebRTC. </p> <p>Here's why it isn't:</p> <p>WebRTC is very heavy. It mandates support for things such as ICE, DTLS, etc.</p> <p>ICE often leads to long session establishment times because ICE candidates need to be collected and evaluated. Yes there is \"Trickle ICE\" but that's another rant for another day.</p> <p>DTLS is fairly heavy too.</p> <p>WebRTC is very cool and offers many advantages. However, most of those advantages relate to WebRTC's ability to establish bidirectional media stream flow between two previously unknown peer devices that can both be behind NAT. We don't have that issue as the streaming server is expected to either be local or at an establish address that isn't behind NAT.</p> <p>However, because we do use HTTP (currently) you can still have both devices behind NAT as long as you properly forward HTTP/HTTPS through your NAT device. None of this really applies if you are locally self-hosting your inference server. So, in short, we feel that WebRTC isn't appropriate or necessary for Willow.</p>"},{"location":"how-willow-works/#willow-inference-server-mode-flow","title":"Willow Inference Server Mode Flow","text":"<pre><code>graph TB\n  A[Wake word] --&gt; B[Start recording] --&gt; C[Stream in real time to inference server] --&gt; D[VAD detects end of speech] --&gt; E[End stream] --&gt; F[Willow Inference Server performs speech to text] --&gt; G[JSON response with text and language] --&gt; H[Send to configured command endpoint] --&gt; I[Depending on configuration play success/failure tone or text to speech result]  --&gt; J[Display speech to text results and command endpoint output]</code></pre>"},{"location":"how-willow-works/#local-mode-flow","title":"Local Mode Flow","text":"<pre><code>graph TB\n A[Wake word] --&gt; B[MultiNet] --&gt; C[MultiNet returns detected command ID] --&gt; D[Look up corresponding text for command] --&gt; E[Send text to configured command endpoint] --&gt; F[Play success/failure tone] --&gt; G[Display speech to text results and command endpoint output]</code></pre>"},{"location":"how-willow-works/#current-status","title":"Current Status","text":"<p>As of this writing (Sep 1 2023) Willow is based on the ADF 2.5 release. This release is fairly old and is based on IDF 4.4. There are many things to look forward to in the upcoming ADF 2.6 release which is based on ESP IDF 5.x. Support for ESP-IDF 5.x has been merged in the main ADF branch and we have a Willow branch where we have started initial work to support ADF 2.6.</p> <p>We have a few outstanding issues that we feel are better off waiting for the release of ADF 2.6 before we begin work on them. We are following the progress of official ADF support for IDF 5.x and will merge our idf5 branch when we feel it is ready.</p>"},{"location":"quick-start-guide/","title":"Quick Start Guide","text":""},{"location":"quick-start-guide/#overview","title":"Overview","text":"<p>Willow is more than the software that runs on the device. Willow has a couple of additional components to enable full Willow functionality.</p> <p>The Willow Application Server is required to manage and configure your Willow devices and needs to be installed before you can flash them.</p>"},{"location":"quick-start-guide/#install-was","title":"Install WAS","text":"<p>We provide a WAS docker image to get you up and running quickly. To start:</p> <pre><code>docker run --detach --name=willow-application-server --pull=always --network=host --restart=unless-stopped --volume=was-storage:/app/storage ghcr.io/toverainc/willow-application-server:main\n</code></pre>"},{"location":"quick-start-guide/#access-was","title":"Access WAS","text":"<p>To access your running WAS instance you will need to know the IP address/host of the machine running WAS. If you don't know the IP address you can start by trying the IP address of the default interface.</p> <p>On the machine running the WAS container:</p> <pre><code>ip route get 1.1.1.1 | grep -oP 'src \\K\\S+'\n</code></pre> <p>For example, if this command outputs 192.168.1.1 your WAS URL is <code>http://192.168.1.1:8501</code></p> <p>Open your WAS address in a web browser on a network that can reach it.</p>"},{"location":"quick-start-guide/#configuring-willow-with-was","title":"Configuring Willow with WAS","text":"<p>When running WAS for the first time you will be instructed to go to the Configuration tab. In the Configuration tab, you will have to configure the WAS URL and Wi-Fi credentials in the Connectivity section and click Save when done. </p> <p>Then expand the Main settings section, choose your Willow Command Endpoint, and enter the required details to connect to it. As we implemented connectivity checks, these details will have to be correct. Click Save here as well. When both Connectivity and Main settings are saved, a link to Willow Web Flash will appear in the Configuration tab. Open this link.</p> <p>Warning</p> <p>At the time of writing, only Chrome (or Chromium), Edge and Opera support the Web Serial API. You must use one of these browsers for Willow Web Flash.</p>"},{"location":"quick-start-guide/#flash-willow-from-willow-web-flash","title":"Flash Willow from Willow Web Flash","text":"<p>In Willow Web Flash, first click Connect. Select your Willow device port from the pop-up and click Pair. Input fields for the WAS URL and Wi-Fi credentials should appear. Enter the correct Wi-Fi credentials, verify the WAS URL, select the hardware you are trying to flash, and click Flash. This will do a full flash of your new Willow device so it will take a few minutes. Once flashing finishes the device should boot Willow and connect to your WAS instance. Head back to the WAS web interface and verify your Willow device is connected in the Home or Clients tab.</p>"},{"location":"quick-start-guide/#enjoy-your-new-willow-voice-assistant","title":"Enjoy your new Willow Voice Assistant!","text":"<p>Once your Willow device is flashed and connected to WAS you can dynamically update its settings. Applying changes will reboot the device with the new settings. Should you enter a wrong WAS URL or Wi-Fi credentials, you will have to do a full flash with Willow Web Flash again to recover your Willow device.</p> <p>Your Willow device is now up and running. If you want to completely self host Willow you can install and configure some additional components:</p>"},{"location":"quick-start-guide/#recommended-deploy-your-own-willow-inference-server-wis","title":"Recommended - Deploy your own Willow Inference Server (WIS)","text":"<p>By default Willow uses a Willow Inference Server hosted by Tovera so users can get up and running quickly. However, the entire goal of Willow is to be completely under your control and self-hosted. With the Tovera hosted WIS instance you're just sending your audio to us instead of Amazon, Google, etc! We don't log or store anything but we strongly encourage users to setup and configure their own WIS instance.</p>"},{"location":"quick-start-guide/#optional-deploy-your-own-willow-web-flasher","title":"Optional - Deploy your own Willow Web Flasher","text":"<p>It may seem strange to enter your Wi-Fi credentials in a random web page but with our hosted web flasher your configuration values never leave your browser. You can verify this by inspecting the code in your browser or viewing the network traffic with browser developer tools.</p> <p>We provide this hosted flashing interface because browsers have very strict rules and requirements when running the Web Serial standard that our flashing tool uses to access your local Willow devices from the browser.</p> <p>If you can manage the TLS certificate issues, etc you can deploy your own Willow Web Flash tool anywhere you want. Get started by visiting the Willow Web Flash Git repository.</p>"},{"location":"what-willow-is/","title":"What Willow Is (And Isn\u2019t)","text":"<p>Willow itself is not a complete and direct replacement for Amazon Echo/Google Home. Willow has a fairly limited focus:</p> <ul> <li>Support wake word to start capturing speech.</li> <li>Use VAD to know when you stop talking.</li> <li>Get the cleanest and highest quality audio possible.</li> <li>Do something useful with the audio (stream to a server for speech to text or use local command recognition).</li> <li>Send the output text to something to do actually do something.</li> <li>Depending on configuration either play success/failure tone or speak output with TTS from WIS.</li> <li>Show speech transcript and command status on display.</li> </ul> <p>That's it!</p>"},{"location":"what-willow-is/#the-future-in-no-particular-order","title":"The Future (in no particular order)","text":""},{"location":"what-willow-is/#performance-improvements","title":"Performance Improvements","text":"<p>Willow and Willow Inference Server/Multinet already provide \"faster-than-Alexa\" responsiveness for a voice user interface. However, there are multiple obvious optimizations we're aware of:</p> <ul> <li>ESP ADF pipeline handing (we're waiting on ESP-ADF 2.6 with ESP-IDF 5)</li> <li>Websockets for inference server (avoids TLS handshake and connection establishment for each session)</li> <li>Code in general (we're new to ESP IDF and it could use review)</li> <li>Various performance-related sdkconfig parameters (again, we're new to ESP IDF)</li> <li>Likely many, many more</li> </ul> <p>These enhancements alone should dramatically improve responsiveness.</p>"},{"location":"what-willow-is/#no-cuda","title":"No CUDA","text":"<p>The Willow Inference Server will run CPU only but the performance on CPU is not comparable to heavily optimized implementations like whisper.cpp. For an Alexa/Echo competitive voice interface we currently believe that our approach with CUDA or local Multinet (up to 400 commands) is the best approach. However, we also understand that isn't practical or preferred for many users. Between on device Multinet command recognition and further development on CPU-only Whisper implementations, ROCm, etc. we will get there. That said, if you can make the audio streaming API work you can use any speech to text and text to speech implementation you want!</p>"},{"location":"what-willow-is/#tts-output","title":"TTS Output","text":"<p>Given the capabilities of Whisper speech commands like \"What is the weather in Sofia, Bulgaria?\" are transcribed but need to match a command (like a Home Assistant intent or openHAB Action Template Interpreter) on the destination. Our inference server implementation has a text to speech engine we will be utilizing. In the event the final response to a given command results in audio output we can play that via the speakers in the ESP BOX (not yet supported).</p>"},{"location":"what-willow-is/#lcd-and-touchscreen-improvements","title":"LCD and Touchscreen Improvements","text":"<p>The ESP BOX has a multi-point capacitive touchscreen and support for many GUI elements. We currently only provide basic features like touch screen to wake up, a little finger cursor thing, and a Cancel button to cancel/interrupt command streaming. There's a lot more work to do here!</p>"},{"location":"what-willow-is/#buttons","title":"Buttons","text":"<p>The ESP BOX has buttons and who doesn't like configuring buttons to do things?!</p>"},{"location":"what-willow-is/#audio-on-device","title":"Audio on device","text":"<p>We have built in success and error tones but we would like to include audio for basic error and status conditions on the device. This will depend on our default text to speech engine selection so we can ensure we provide a consistent voice user interface and experience.</p>"},{"location":"what-willow-is/#multiple-devices","title":"Multiple Devices","text":"<p>The good news is the far-field wake word recognition and speech recognition performance is very good. The bad news is if you have multiple devices in proximity they are all likely to wake and process speech simultaneously. Commands will still work but multiple confirmation/error beeps and hammering your destination command endpoint is less than ideal. We have a few ideas about dealing with this too.</p>"},{"location":"what-willow-is/#custom-wake-word","title":"Custom Wake Word","text":"<p>Espressif has a wake word customization service that enables us (and commercial users) to create custom wake words. We plan to create a \"Hi Willow\" or similar wake word and potentially others depending on input from the community.</p>"},{"location":"what-willow-is/#gpio","title":"GPIO","text":"<p>The ESP BOX provides 16 GPIOs to the user that are readily accessed from sockets on the rear of the device. We plan to make these configurable by the user to enable all kinds of interesting maker/DIY functions.</p>"},{"location":"willow-components/","title":"Willow Components","text":""},{"location":"willow-components/#willow-application-server","title":"Willow Application Server","text":"<p>The Willow Application Server (WAS) is a web-based component that facilitates dynamic configuration, Over-the-Air (OTA) updates, and basic monitoring.</p>"},{"location":"willow-components/#willow-web-flash","title":"Willow Web Flash","text":"<p>Willow Web Flash is a web-based component that facilitates the initial flash of the Willow firmware image on supported hardware. It uses the Web Serial API, which is only available on secure websites. As any secure website requires TLS certificates, which is not something we can expect end users to deal with themselves, we provide a public instance of Willow Web Flash. It will require entering your Wi-Fi credentials, as they need to be injected in the Willow firmware image before flashing it, but these credentials will never leave your browser. Willow Web Flash is based on Espressif's esptool-js, and is 100% open source. You can inspect the source to validate our claim the Wi-Fi credentials never leave the browser.</p>"},{"location":"willow-components/#how-it-works","title":"How it works","text":"<p>Using Willow with WAS consists of a few steps:</p> <ul> <li>deploy WAS from our published container image</li> <li>configure your Wi-Fi credentials, the WAS URL for your Willow device(s), and the Willow settings</li> <li>head to Willow Web Flash from the link provided in WAS and flash Willow</li> <li>once the initial flash via Willow Web Flash is done, Willow can be updated Over-the-Air from WAS, and using Willow Web Flash should only be needed for recovery in case something goes wrong</li> </ul> <p>We have tried to make the experience as easy as possible. * we try to guess the WAS URL * we check connectivity for the various URLs configured in WAS * we pass the WAS URL to Willow Web Flash and save it in local browser storage   (for security reasons we do not pass the Wi-Fi credentials)</p>"},{"location":"components/willow-application-server/","title":"Willow Application Server  (WAS)","text":"<p>The Willow Application Server provides:</p> <ul> <li>Dynamic configuration. Update the configuration across all of your devices with a single click.</li> <li>Updates. WAS can fetch the most recent Willow releases and apply them to your devices over the air.</li> </ul>"},{"location":"components/willow-application-server/#getting-started","title":"Getting Started","text":"<p>We have tried to simplify the onboarding process as much as possible. It is no longer required to build Willow yourself. All you have to do is run Willow Application Server and connect to it. From there, you will be guided to the Willow Web Flasher, which will download a Willow dist image from Github, inject your Wi-Fi credentials into the NVS partition, and flash it to your device.</p>"},{"location":"components/willow-application-server/#running-was","title":"Running WAS","text":"<pre><code>docker run --detach --name=willow-application-server --pull=always --network=host --restart=unless-stopped --volume=was-storage:/app/storage ghcr.io/toverainc/willow-application-server:main\n</code></pre>"},{"location":"components/willow-application-server/#building-was","title":"Building WAS","text":"<pre><code>git clone https://github.com/toverainc/willow-application-server.git &amp;&amp; cd willow-application-server\n\n./utils.sh build\n</code></pre>"},{"location":"components/willow-application-server/#start","title":"Start","text":"<p><code>./utils.sh run</code></p>"},{"location":"components/willow-application-server/#configure-and-update-willow-devices","title":"Configure and update Willow devices","text":"<p>Visit <code>http://my_was_host:8501</code> in your browser.</p>"},{"location":"components/willow-application-server/#ota","title":"OTA","text":"<p>We list releases with OTA assets. Select the wanted release and click the OTA button. If the release is not already cached in WAS, WAS will download the binary from Github and cache it, then instruct Willow to start OTA with the URL of the cached asset. This makes it possible to run Willow in an isolated VLAN without Internet access.</p> <p>To use a self-built binary for OTA, place it in the the ota/local directory of the was-storage volume using the following filenames: * willow-ota-ESP32_S3_BOX.bin * willow-ota-ESP32_S3_BOX_LITE.bin</p> <p>To copy the file to the running container:</p> <pre><code>docker cp build/willow.bin willow-application-server:/app/storage/ota/local/willow-ota-ESP32_S3_BOX.bin\n</code></pre>"},{"location":"components/willow-inference-server/","title":"Willow Inference Server (WIS)","text":"<p>Willow Inference Server  (WIS) is a focused and highly optimized language inference server implementation. Our goal is to \"automagically\" enable performant, cost-effective self-hosting of released state of the art/best of breed models to enable speech and language tasks:</p> <ul> <li>Primarily targeting CUDA with support for low-end (cheap) devices such as the Tesla P4, GTX 1060, and up. Don't worry - it screams on an RTX 4090 too! (See benchmarks). Can also run CPU-only.</li> <li>Memory optimized - all three default Whisper (base, medium, large-v2) models loaded simultaneously with TTS support inside of 6GB VRAM. LLM support defaults to int4 quantization (conversion scripts included). ASR/STT + TTS + Vicuna 13B require roughly 18GB VRAM. Less for 7B, of course!</li> <li>ASR. Heavy emphasis - Whisper optimized for very high quality as-close-to-real-time-as-possible speech recognition via a variety of means (Willow, WebRTC, POST a file, integration with devices and client applications, etc). Results in hundreds of milliseconds or less for most intended speech tasks.</li> <li>TTS. Primarily provided for assistant tasks (like Willow!) and visually impaired users.</li> <li>LLM. Optionally pass input through a provided/configured LLM for question answering, chatbot, and assistant tasks. Currently supports LLaMA derivatives with strong preference for Vicuna (the author likes 13B). Built in support for quantization to int4 to conserve GPU memory.</li> <li>Support for a variety of transports. REST, WebRTC, Web Sockets (primarily for LLM).</li> <li>Performance and memory optimized. Leverages CTranslate2 for Whisper support and AutoGPTQ for LLMs.</li> <li>Willow support. WIS powers the Tovera hosted best-effort example server Willow users enjoy.</li> <li>Support for WebRTC - stream audio in real-time from browsers or WebRTC applications to optimize quality and response time. Heavily optimized for long-running sessions using WebRTC audio track management. Leave your session open for days at a time and have self-hosted ASR transcription within hundreds of milliseconds while conserving network bandwidth and CPU!</li> <li>Support for custom TTS voices. With relatively small audio recordings WIS can create and manage custom TTS voices. See API documentation for more information.</li> </ul> <p>With the goal of enabling democratization of this functionality WIS will detect available CUDA VRAM, compute platform support, etc and optimize and/or disable functionality automatically (currently in order - ASR, TTS, LLM). For all supported Whisper models (large-v2, medium, and base) loaded simultaneously current minimum supported hardware is GTX 1060 3GB (6GB for ASR and TTS). User applications across all supported transports are able to programmatically select and configure Whisper models and parameters (model size, beam, language detection/translation, etc) and TTS voices on a per-request basis depending on the needs of the application to balance speed/quality.</p> <p>Note that we are primarily targeting CUDA - the performance, cost, and power usage of cheap GPUs like the Tesla P4 and GTX 1060 is too good to ignore. We'll make our best effort to support CPU wherever possible for current and future functionality but our emphasis is on performant latency-sensitive tasks even with low-end GPUs like the GTX 1070/Tesla P4 (as of this writing roughly $100 USD on the used market - and plenty of stock!).</p>"},{"location":"components/willow-inference-server/#getting-started","title":"Getting Started","text":""},{"location":"components/willow-inference-server/#dependencies-run-once-for-initial-install","title":"Dependencies (run once for initial install)","text":"<p>For CUDA support you will need to have the NVIDIA drivers for your supported hardware. We recommend Nvidia driver version 530.</p> <pre><code># Clone this repo:\ngit clone https://github.com/toverainc/willow-inference-server.git &amp;&amp; cd willow-inference-server\n\n# Ensure you have nvidia-container-toolkit and not nvidia-docker\n# On Arch Linux:\nyay -S libnvidia-container-tools libnvidia-container nvidia-container-toolkit docker-buildx\n\n# Ubuntu:\n./deps/ubuntu.sh\n</code></pre>"},{"location":"components/willow-inference-server/#install-configure-and-start-wis","title":"Install, configure, and start WIS","text":"<pre><code># Install\n./utils.sh install\n\n# Generate self-signed TLS cert (or place a \"real\" one at nginx/key.pem and nginx/cert.pem)\n./utils.sh gen-cert [your hostname]\n\n# Start WIS\n./utils.sh run\n</code></pre>"},{"location":"components/willow-inference-server/#links-and-resources","title":"Links and Resources","text":"<p>Willow: Configure Willow to use <code>https://[your host]:19000/api/willow</code> then build and flash.</p> <p>WebRTC demo client: <code>https://[your host]:19000/rtc</code></p> <p>API documentation for REST interface: <code>https://[your host]:19000/api/docs</code></p>"},{"location":"components/willow-inference-server/#configuration","title":"Configuration","text":"<p>System runtime can be configured by placing a <code>.env</code> file in the WIS root to override any variables set by <code>utils.sh</code>. You can also change more WIS specific parameters by copying <code>settings.py</code> to <code>custom_settings.py</code>.</p>"},{"location":"components/willow-inference-server/#windows-support","title":"Windows Support","text":"<p>WIS has been successfully tested on Windows with WSL (Windows Subsystem for Linux). With ASR and STT only requiring a total of 4GB VRAM WIS can be run concurrently with standard Windows desktop tasks on GPUs with 8GB VRAM.</p>"},{"location":"components/willow-inference-server/#benchmarks","title":"Benchmarks","text":"Device Model Beam Size Speech Duration (ms) Inference Time (ms) Realtime Multiple RTX 4090 large-v2 5 3840 140 27x RTX 3090 large-v2 5 3840 219 17x H100 large-v2 5 3840 294 12x H100 large-v2 5 10688 519 20x H100 large-v2 5 29248 1223 23x GTX 1060 large-v2 5 3840 1114 3x Tesla P4 large-v2 5 3840 1099 3x GTX 1070 large-v2 5 3840 742 5x RTX 4090 medium 1 3840 84 45x RTX 3090 medium 1 3840 140 27x GTX 1070 medium 1 3840 424 9x GTX 1070 medium 1 10688 564 18x GTX 1070 medium 1 29248 1118 26x GTX 1060 medium 1 3840 588 6x Tesla P4 medium 1 3840 586 6x RTX 4090 medium 1 29248 377 77x RTX 3090 medium 1 29248 520 56x GTX 1060 medium 1 29248 1612 18x Tesla P4 medium 1 29248 1730 16x GTX 1070 base 1 3840 70 54x GTX 1070 base 1 10688 92 115x GTX 1070 base 1 29248 195 149x RTX 4090 base 1 180000 277 648x (not a typo) RTX 3090 base 1 180000 435 414x (not a typo) RTX 3090 tiny 1 180000 366 491x (not a typo) GTX 1070 tiny 1 3840 46 82x GTX 1070 tiny 1 10688 64 168x GTX 1070 tiny 1 29248 135 216x Threadripper PRO 5955WX tiny 1 3840 140 27x Threadripper PRO 5955WX base 1 3840 245 15x Threadripper PRO 5955WX small 1 3840 641 5x Threadripper PRO 5955WX medium 1 3840 1614 2x Threadripper PRO 5955WX large 1 3840 3344 1x <p>As you can see the realtime multiple increases dramatically with longer speech segments. Note that these numbers will also vary slightly depending on broader system configuration - CPU, RAM, etc.</p> <p>When using WebRTC or Willow end-to-end latency in the browser/Willow and supported applications is the numbers above plus network latency for response - with the advantage being you can skip the \"upload\" portion as audio is streamed in realtime!</p> <p>We are very interested in working with the community to optimize WIS for CPU. We haven't focused on it because we consider medium beam 1 to be the minimum configuration for intended tasks and CPUs cannot currently meet our latency targets.</p>"},{"location":"components/willow-inference-server/#comparison-benchmarks","title":"Comparison Benchmarks","text":"<p>Raspberry Pi Benchmarks run on Raspberry Pi 4 4GB Debian 11.7 aarch64 with faster-whisper version 0.5.1. Canakit 3 AMP USB-C power adapter and fan. All models int8 with <code>OMP_NUM_THREADS=4</code> and language set as en. Same methodology as timing above with model load time excluded (WIS keeps models loaded). All inference time numbers rounded down. Max temperatures as reported by <code>vcgencmd measure_temp</code> were 57.9 C.</p> Device Model Beam Size Speech Duration (ms) Inference Time (ms) Realtime Multiple Pi tiny 1 3840 3333 1.15x Pi base 1 3840 6207 0.62x Pi medium 1 3840 50807 0.08x Pi large-v2 1 3840 91036 0.04x"},{"location":"components/willow-inference-server/#cuda","title":"CUDA","text":"<p>We understand the focus and emphasis on CUDA may be troubling or limiting for some users. We will provide additional CPU vs GPU benchmarks but spoiler alert: a $100 used GPU from eBay will beat the fastest CPUs on the market while consuming less power at SIGNIFICANTLY lower cost. GPUs are very fundamentally different architecturally and while there is admirable work being done with CPU optimized projects such as whisper.cpp and CTranslate2 we believe that GPUs will maintain drastic speed, cost, and power advantages for the forseeable future. That said, we are interested in getting feedback (and PRs!) from WIS users to make full use of CTranslate2 to optimize for CPU.</p>"},{"location":"components/willow-inference-server/#gpu-sweet-spot-may-2023","title":"GPU Sweet Spot - May 2023","text":"<p>Perusing eBay and other used marketplaces the GTX 1070 seems to be the best performance/price ratio for ASR/STT and TTS while leaving VRAM room for the future. The author ordered an EVGA GTX 1070 FTW ACX3.0 for $120 USD with shipping and tax on 5/19/2023.</p> <p>To support LLM/Vicuna an RTX 3090/4090 is suggested. RTX 3090 being sold for approximately $800 as of this writing (5/23/2023).</p>"},{"location":"components/willow-inference-server/#llm","title":"LLM","text":"<p>WIS supports LLM on compatible CUDA devices with sufficient memory (varies depending on model selected).</p> <p>From WIS root:</p> <p><code>cp settings.py custom_settings.py</code></p> <p>Edit <code>custom_settings.py</code> and set <code>chatbot_model_path</code> to an AutoGPTQForCausalLM compatible model path from Hugging Face (example provided). The model will be automatically downloaded, cached, and loaded from Hugging Face. Depending on the GPTQ format and configuration for your chosen model you may need to also change <code>chatbot_model_basename</code>. The various other parameters (temperature, top_p, etc) can also be set in <code>custom_settings.py</code> (defaults provided).</p> <p>Make sure to set <code>support_chatbot</code> to <code>True</code>.</p> <p>Then start/restart WIS.</p> <p>Once loaded you can view the chatbot API documentation at <code>https://[your host]:19000/api/docs</code>.</p>"},{"location":"components/willow-inference-server/#webrtc-tricks","title":"WebRTC Tricks","text":"<p>The author has a long background with VoIP, WebRTC, etc. We deploy some fairly unique \"tricks\" to support long-running WebRTC sessions while conserving bandwidth and CPU. In between start/stop of audio record we pause (and then resume) the WebRTC audio track to bring bandwidth down to 5 kbps at 5 packets per second at idle while keeping response times low. This is done to keep ICE active and any NAT/firewall pinholes open while minimizing bandwidth and CPU usage. Did I mention it's optimized?</p> <p>Start/stop of sessions and return of results uses WebRTC data channels.</p>"},{"location":"components/willow-inference-server/#webrtc-client-library","title":"WebRTC Client Library","text":"<p>See the Willow TypeScript Client repo to integrate WIS WebRTC support into your own frontend.</p>"},{"location":"components/willow-inference-server/#fun-ideas","title":"Fun Ideas","text":"<ul> <li>Integrate WebRTC with Home Assistant dashboard to support streaming audio directly from the HA dashboard on desktop or mobile.</li> <li>Desktop/mobile transcription apps (look out for a future announcement on this!).</li> <li>Desktop/mobile assistant apps - Willow everywhere!</li> </ul>"},{"location":"components/willow-inference-server/#the-future-in-no-particular-order","title":"The Future (in no particular order)","text":""},{"location":"components/willow-inference-server/#better-tts","title":"Better TTS","text":"<p>We're looking for feedback from the community on preferred implementations, voices, etc. See the open issue.</p>"},{"location":"components/willow-inference-server/#tts-caching","title":"TTS Caching","text":"<p>Why do it again when you're saying the same thing? Support on-disk caching of TTS output for lightning fast TTS response times.</p>"},{"location":"components/willow-inference-server/#support-for-more-languages","title":"Support for More Languages","text":"<p>Meta released MMS on 5/22/2023, supporting over 1,000 languages across speech to text and text to speech!</p>"},{"location":"components/willow-inference-server/#code-refactoring-and-modularization","title":"Code Refactoring and Modularization","text":"<p>WIS is very early and we will refactor, modularize, and improve documentation well before the 1.0 release.</p>"},{"location":"components/willow-inference-server/#chaining-of-functions-apps","title":"Chaining of Functions (Apps)","text":"<p>We may support user-defined modules to chain together any number of supported tasks within one request, enabling such things as:</p> <p>Speech in -&gt; LLM -&gt; Speech out</p> <p>Speech in -&gt; Arbitrary API -&gt; Speech out</p> <p>...and more, directly in WIS!</p>"},{"location":"features/Home-Assistant/","title":"Home Assistant","text":""},{"location":"features/Home-Assistant/#the-year-of-voice","title":"The Year of Voice!","text":"<p>Home Assistant has taken on the task of doing the heavy lifting with privacy focused, user controlled speech interfaces. Willow truly stands on the shoulders of this giant. Willow would not be useful without all of the hard work of the Home Assistant team over the years.</p> <p>All of the developers in the Willow project have enjoyed the use of Home Assistant over the years and in my case, for nearly a decade. It's amazing!</p>"},{"location":"features/Home-Assistant/#why-willow-where-does-it-fit-in","title":"Why Willow? Where does it fit in?","text":"<p>The Home Assistant team has made incredible progress on speech this year! We're aware they're working on things like wake word, etc. We started work on Willow because we love Home Assistant and we've always thought the ESP32-S3-BOX hardware was cool and a perfect fit for use with it.</p> <p>However, as limited in focus as Willow is it turns out this isn't an easy task. The ESP32-S3-BOX hardware is very, very capable but the development environment is somewhat challenging for someone like myself who at best can whip up a quick and dirty Python script. C! Microcontroller! Balancing IRAM vs PSRAM! All kinds of overlapping frameworks! Flashing, and flashing, and flashing during dev! It's been a journey but we are happy with the initial results.</p> <p>The Home Assistant project has spoken of the concept of \"voice satellites\". From what I can gather the thinking is this:</p> <ul> <li>They target a bunch of platforms, including relatively light ones like the Raspberry Pi.</li> <li>These voice satellites can be placed throughout an environment to pretty much do what Willow does.</li> <li>They already have a cool demo of the M5stack (integrated with esphome!) with push to talk!</li> </ul> <p>Problem is you're not going to replace Amazon Echo without wake word, VAD, LCD display, etc. As noted by the Home Assistant team these features are surprisingly difficult to implement (from what I remember their anticipated speech and wake engine is proprietary). From what I understand they're working on support of these with the Raspberry Pi.</p> <p>However, we feel using a Raspberry Pi or similar device isn't well suited for this task:</p> <ul> <li>Due to supply chain issues they are difficult to come by.</li> <li>By the time you factor in the board, SD card, enclosure, power supply, LCD display, microphones, etc, etc the BOM (bill of materials) is significantly more expensive (likely 3x) than the ESP32-S3-BOX hardware.</li> <li>It's very \"DIY\" and for many people would result in a mess of wires or at best a 3D printed case.</li> <li>There are acoustic challenges to provide high quality far-field audio. All kinds of audio stuff involving the enclosure, etc that I don't understand.</li> <li>It's relatively heavy from a power consumption standpoint.</li> </ul> <p>Knowing the awesomeness that is Home Assistant and the team I'm sure they're working on these issues and will have their own complete solution soon.</p>"},{"location":"features/Home-Assistant/#the-future","title":"The future","text":"<p>We would love to work with the Home Assistant team to enable tighter integration of Willow with Home Assistant as a \"voice satellite\". This could enable such things as:</p> <ul> <li>Use your Home Assistant server/HASSIO as the inference server for Willow.</li> <li>Configure Willow completely through Home Assistant.</li> <li>Use any of the Home Assistant TTS/STT components.</li> <li>Flash Willow to supported hardware directly via Home Assistant (like esphome).</li> <li>Much, much more!</li> </ul>"},{"location":"features/Home-Assistant/#other-platforms","title":"Other Platforms","text":"<p>We feel Willow has the potential to enable all kinds of interesting voice applications outside of use with Home Assistant (commercial or otherwise). We welcome work on Willow integrations/modules as it makes sense - other HA systems, generic inputs/outputs, other protocols, custom applications, etc.</p>"},{"location":"features/Local-Command-Support/","title":"Local Command Support","text":""},{"location":"features/Local-Command-Support/#multinet","title":"MultiNet","text":"<p>Willow supports \"local command recognition\" via the MultiNet model provided by ESP-SR.</p>"},{"location":"features/Local-Command-Support/#why-its-cool","title":"Why It's Cool","text":"<p>Willow hardware can do completely local command detection with MultiNet. This has many advantages:</p> <ul> <li>No additional servers.</li> <li>FAST response time. Seriously, it's unbelievably fast!</li> <li>With up to 400 commands it's quite usable.</li> <li>Better \"fuzzy\" matching. Like any inference model, MultiNet returns probability based on speech input. This has the effect of having better \"fuzzy matching\" for detected speech. So things like \"turn on upstairs lights\" will likely match a grammar definition of \"turn on upstairs light\" (for example).</li> </ul>"},{"location":"features/Local-Command-Support/#multinet-status","title":"MultiNet Status","text":"<p>MultiNet support in Willow is beta (in a project that is beta).</p>"},{"location":"features/Local-Command-Support/#using-multinet","title":"Using MultiNet","text":"<p>You can try MultiNet by enabling it in the Willow Configuration section during <code>./utils.sh config</code>. You need to make sure you're using the PCM codec, which will enable an additional configuration option called \"Use local command detection via MultiNet\".</p> <p>With some hacky stuff in <code>utils.sh build</code> and a disgusting Python script when enabled we will try to do the following:</p> <ul> <li>Connect to your configured Home Assistant instance and get your entities (currently only lights and switches).</li> <li>Build the ESP-SR MultiNet English grammar file with the structure \"TURN ON $ENTITY_FRIENDLY_NAME\" and \"TURN OFF $ENTITY_FRIENDLY_NAME\".</li> <li>As of this writing the MultiNet model only returns the command ID (1-400) associated with the grammar entry.</li> <li>We hack around this by also generating a header file with a map of command ID to friendly text to show on the display/send to the server (Home Assistant).</li> <li>The Python script is fairly conservative because we don't want to crash the device. If this auto configuration results in more than 200 entities (400 max, TURN ON + TURN OFF / 2 = 200) the script will exit and the build will fail.</li> </ul> <p>This is very ugly for a variety of reasons and we're looking for help in this area!</p>"},{"location":"features/Local-Command-Support/#caveats","title":"Caveats","text":"<ul> <li>The models provided by Espressif only support English and Chinese. Willow currently only supports English.</li> <li>We have not tested this with a wide variety of Home Assistant configurations.</li> <li>It's very possible (almost certain) it won't work with one or more of your entity names. For example, the MultiNet model only supports numbers expressed as words (300 = THREE HUNDRED) and only supports commands with a maximum of 63 characters.</li> <li>Because of this issues our auto generation script will drop entities with numbers in their friendly names as we've observed in our testing many entities with friendly names end up running over the 63 character limit anyway.</li> <li>It currently only supports light and switch entities (no reason it can't support others, we're just being cautious).</li> <li>It has a very fixed command format (TURN ON/TURN OFF).</li> <li>It currently doesn't allow users to manually edit names, entities, and grammar.</li> <li>It does very little error checking and you can crash the ESP device fairly easily with unexpected language model definitions/grammar format.</li> <li>Entities and grammar are only defined at build time. The MultiNet model supports defining commands dynamically at runtime and we are investigating approaches to enable automatic definition of entity additions/deletions/changes.</li> </ul> <p>In the future we hope to address these issues with a nice configuration interface for users to define commands and broader dynamic/runtime configuration support.</p>"},{"location":"features/Wi-Fi/","title":"Wi-Fi","text":"<p>Wi-Fi is (essentially) magic to me. I don't pretend to know everything about it but here's the overview as I understand it:</p> <ul> <li>The ESP 32 S3 only supports 2.4 GHz. In many environments the 2.4 GHz Wi-Fi spectrum can be nearly useless as there are plenty of other things sharing this spectrum (from Bluetooth to baby monitors). Additionally, because it has higher penetration through solid objects than 5/6 (Wi-Fi 6E) GHz there's a tendency for higher interference from neighboring Wi-Fi networks, etc.</li> <li>Many people have ridiculous Wi-Fi settings on their routers. If you do a Wi-Fi scan you will probably see neighbors with their devices set to do things like use 40 MHz channel bandwidth, etc.</li> <li>In the United States at least, there are only three non-overlapping 2.4 GHz Wi-Fi channels (1,6,11). This limits the ability for multiple devices and networks to transmit simultaneously.</li> </ul> <p>Because of all of this, getting \"air time\" to transmit on the 2.4 GHz spectrum for higher bandwidth applications like Willow can be challenging. We do our best to support things like frame aggregation, etc but the positive impact of these hacks is hit-or-miss.</p> <p>All of this said, it actually (somehow - magic!) works fairly well. However, in cases where the default setting of streaming raw PCM frames to the inference server has issues due to Wi-Fi bandwidth we (optionally) support audio compression using a codec called AMR-WB.</p>"},{"location":"features/Wi-Fi/#whats-the-deal-with-amr-wb","title":"What's the deal with AMR-WB?","text":"<p>AMR-WB (aka G.722.2) is an old codec that I know from my many (painful) years spent in VoIP. If you've ever used a mobile device AMR-WB is the standard codec cell phone networks use for \"wideband\" audio support so you most likely use it almost everyday without knowing. Wideband audio is generally classified as any audio that has a sampling rate greater than 8 kHz. There's also AMR-WB+ that many cell and cell network devices support but it's not supported by ADF and irrelevant here.</p> <p>Because of the Nyquist-Shannon sampling theorem this is somewhat misleading - long story short the effective audio bandwidth is half of the sample rate, so 8 kHz results in more-or-less 4 kHz audio frequency response. This is not enough to accurately reproduce the full range of human speech and isn't acceptable for our use. Unfortunately, AMR-WB is the only wideband audio codec the ESP ADF framework supports encoding with. In a perfect world we could use something more modern like OPUS that would offer many advantages, including support for even higher sample rates. My hunch is the ESP32 S3 probably has the CPU cycles to use OPUS and we think this would offer many advantages.</p> <p>However, there \"is no free lunch\" as they say. We use the highest bitrate supported by AMR-WB that is allegedly fairly robust in terms of background noise and accurate representation of human speech at 16 kHz. However, users may notice that the speech recognition results from the inference server are not as accurate as they are when using PCM. A codec supporting higher bitrates and more encoding options like OPUS, in additional to some additional processing on the device, could alleviate some of these issues.</p>"},{"location":"features/Wi-Fi/#compatibility","title":"Compatibility","text":"<p>There are practically millions of variables with Wi-Fi. ESP devices are Wi-Fi devices at their core and have been used on many Wi-Fi networks successfully. We feel confident that due to this Willow provides wide compatibility with various Wi-Fi network configurations but there's no way to tell if it's going to work for you.</p> <p>If you have Wi-Fi problems let us know and we'll do our best within the limits of hardware support, software support, and physics to support Willow in your environment.</p>"},{"location":"features/Wi-Fi/#my-wi-fi-sucks","title":"My Wi-Fi Sucks","text":"<p>In the event you have an especially challenging Wi-Fi environment you can try using AMR-WB. It can be enabled during configuration in the Willow Configuration section by selecting \"AMR-WB\" under the \"Audio codec to use\" section. Try it out and let us know if it works for you!</p> <p>For Wi-Fi experts (PLEASE HELP) you can also look at the various Wi-Fi options available under the Component config section of the configuration menu. However, as noted in the README and elsewhere you're kind of on your own with such changes and we can't claim support for every Wi-Fi network in the world and any changes you may make in this section.</p>"}]}